{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "N8yDV3ItwdnY"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models # add models to the list\n",
    "from torchvision.utils import make_grid\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o24rpjhjwMvO",
    "outputId": "c371c3d4-72bc-4dbf-9b29-0a8133673754"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2577e249d10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hb6BWPIjjrBa",
    "outputId": "30d59a62-110f-448e-d7a3-611818765fe0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1+cpu\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "VsGIDlKfwgMg"
   },
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "TRAIN_DIR = \"data/train\"\n",
    "VAL_DIR = \"data/val\"\n",
    "LEARNING_RATE = 2e-4\n",
    "BATCH_SIZE = 32 #Use a number that can divide the total of photos- (here 961)\n",
    "NUM_WORKERS = 2\n",
    "IMAGE_SIZE = 256\n",
    "CHANNELS_IMG = 3\n",
    "L1_LAMBDA = 100\n",
    "LAMBDA_GP = 10\n",
    "NUM_EPOCHS = 30 #we suggest over 100\n",
    "LOAD_MODEL = False\n",
    "SAVE_MODEL = False\n",
    "CHECKPOINT_DISC = \"disc.pth.tar\"\n",
    "CHECKPOINT_GEN = \"gen.pth.tar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Xc9uu4LswkkV"
   },
   "outputs": [],
   "source": [
    "#Discriminator model for Pix2Pix\n",
    "\n",
    "class CNNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride):\n",
    "        super(CNNBlock, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 4, stride, 1, bias=False, padding_mode=\"reflect\"),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels=3, features=[64, 128, 256, 512]):\n",
    "        super().__init__()\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.Conv2d(in_channels * 2,features[0],kernel_size=4,stride=2,padding=1,padding_mode=\"reflect\"),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "        layers = []\n",
    "        in_channels = features[0]\n",
    "        for feature in features[1:]:\n",
    "            layers.append(\n",
    "                CNNBlock(in_channels, feature, stride=1 if feature == features[-1] else 2),\n",
    "            )\n",
    "            in_channels = feature\n",
    "\n",
    "        layers.append(\n",
    "            nn.Conv2d(\n",
    "                in_channels, 1, kernel_size=4, stride=1, padding=1, padding_mode=\"reflect\"\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x = torch.cat([x, y], dim=1)\n",
    "        x = self.initial(x)\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Jm7rc3ANwvpN"
   },
   "outputs": [],
   "source": [
    "#Generator model for Pix2Pix\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, down=True, act=\"relu\", use_dropout=False):\n",
    "        super(Block, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 4, 2, 1, bias=False, padding_mode=\"reflect\")\n",
    "            if down\n",
    "            else nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU() if act == \"relu\" else nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "        self.use_dropout = use_dropout\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.down = down\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return self.dropout(x) if self.use_dropout else x\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_channels=3, features=64):\n",
    "        super().__init__()\n",
    "        self.initial_down = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, features, 4, 2, 1, padding_mode=\"reflect\"),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        self.down1 = Block(features, features * 2, down=True, act=\"leaky\", use_dropout=False)\n",
    "        self.down2 = Block(features * 2, features * 4, down=True, act=\"leaky\", use_dropout=False)\n",
    "        self.down3 = Block(features * 4, features * 8, down=True, act=\"leaky\", use_dropout=False)\n",
    "        self.down4 = Block(features * 8, features * 8, down=True, act=\"leaky\", use_dropout=False)\n",
    "        self.down5 = Block(features * 8, features * 8, down=True, act=\"leaky\", use_dropout=False)\n",
    "        self.down6 = Block(features * 8, features * 8, down=True, act=\"leaky\", use_dropout=False)\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(features * 8, features * 8, 4, 2, 1,padding_mode=\"reflect\"), nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.up1 = Block(features * 8, features * 8, down=False, act=\"relu\", use_dropout=True)\n",
    "        self.up2 = Block(features * 8 * 2, features * 8, down=False, act=\"relu\", use_dropout=True)\n",
    "        self.up3 = Block(features * 8 * 2, features * 8, down=False, act=\"relu\", use_dropout=True)\n",
    "        self.up4 = Block(features * 8 * 2, features * 8, down=False, act=\"relu\", use_dropout=False)\n",
    "        self.up5 = Block(features * 8 * 2, features * 4, down=False, act=\"relu\", use_dropout=False)\n",
    "        self.up6 = Block(features * 4 * 2, features * 2, down=False, act=\"relu\", use_dropout=False)\n",
    "        self.up7 = Block(features * 2 * 2, features, down=False, act=\"relu\", use_dropout=False)\n",
    "        self.final_up = nn.Sequential(\n",
    "            nn.ConvTranspose2d(features * 2, in_channels, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        d1 = self.initial_down(x)\n",
    "        d2 = self.down1(d1)\n",
    "        d3 = self.down2(d2)\n",
    "        d4 = self.down3(d3)\n",
    "        d5 = self.down4(d4)\n",
    "        d6 = self.down5(d5)\n",
    "        d7 = self.down6(d6)\n",
    "        bottleneck = self.bottleneck(d7)\n",
    "        up1 = self.up1(bottleneck)\n",
    "        up2 = self.up2(torch.cat([up1, d7], 1))\n",
    "        up3 = self.up3(torch.cat([up2, d6], 1))\n",
    "        up4 = self.up4(torch.cat([up3, d5], 1))\n",
    "        up5 = self.up5(torch.cat([up4, d4], 1))\n",
    "        up6 = self.up6(torch.cat([up5, d3], 1))\n",
    "        up7 = self.up7(torch.cat([up6, d2], 1))\n",
    "        return self.final_up(torch.cat([up7, d1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "aPL878jTwy2m"
   },
   "outputs": [],
   "source": [
    "#Train function for Pix2Pix\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "def train_fn(disc, gen, loader, opt_disc, opt_gen, l1_loss, bce, g_scaler, d_scaler,):\n",
    "    loop = tqdm(loader, leave=True)\n",
    "\n",
    "    for idx, (x, y) in enumerate(loop):\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "\n",
    "        # Train Discriminator\n",
    "        with torch.cuda.amp.autocast():\n",
    "            y_fake = gen(x)\n",
    "            D_real = disc(x, y)\n",
    "            D_fake = disc(x, y_fake.detach())\n",
    "            D_real_loss = bce(D_real, torch.ones_like(D_real))\n",
    "            D_fake_loss = bce(D_fake, torch.zeros_like(D_fake))\n",
    "            D_loss = (D_real_loss + D_fake_loss) / 2\n",
    "\n",
    "        disc.zero_grad()\n",
    "        d_scaler.scale(D_loss).backward()\n",
    "        d_scaler.step(opt_disc)\n",
    "        d_scaler.update()\n",
    "\n",
    "        # Train generator\n",
    "        with torch.cuda.amp.autocast():\n",
    "            D_fake = disc(x, y_fake)\n",
    "            G_fake_loss = bce(D_fake, torch.ones_like(D_fake))\n",
    "            L1 = l1_loss(y_fake, y) * L1_LAMBDA\n",
    "            G_loss = G_fake_loss + L1\n",
    "\n",
    "        opt_gen.zero_grad()\n",
    "        g_scaler.scale(G_loss).backward()\n",
    "        g_scaler.step(opt_gen)\n",
    "        g_scaler.update()\n",
    "\n",
    "        if idx % 10 == 0:\n",
    "            loop.set_postfix(\n",
    "                D_real=torch.sigmoid(D_real).mean().item(),\n",
    "                D_fake=torch.sigmoid(D_fake).mean().item(),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "h_7H3bXls8bR"
   },
   "outputs": [],
   "source": [
    "# Utils for Pix2Pix\n",
    "\n",
    "def save_some_examples(gen, val_loader, epoch, folder):\n",
    "  ##ADDITION\n",
    "    y_pred = []\n",
    "  ##\n",
    "\n",
    "    x, y = next(iter(val_loader))\n",
    "    x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "    gen.eval()\n",
    "    with torch.no_grad():\n",
    "        y_fake = gen(x)\n",
    "        y_fake = y_fake * 0.5 + 0.5  # remove normalization#\n",
    "\n",
    "        ##ADDITION\n",
    "        y_prediction = y_fake.cpu().numpy() #convert pytorch tensor to numpy\n",
    "        y_pred.append(y_prediction)\n",
    "        ##\n",
    "\n",
    "        save_image(y_fake, folder + f\"/y_gen_{epoch}.png\")\n",
    "        save_image(x * 0.5 + 0.5, folder + f\"/input_{epoch}.png\")\n",
    "        if epoch == 1:\n",
    "            save_image(y * 0.5 + 0.5, folder + f\"/label_{epoch}.png\")\n",
    "    gen.train()\n",
    "\n",
    "    ##ADDITION\n",
    "    ypred = np.array(y_pred)\n",
    "    #print(ypred)\n",
    "    np.save(\"ypred.npy\", ypred)\n",
    "    ##\n",
    "\n",
    "\n",
    "def save_checkpoint(model, optimizer, filename=\"my_checkpoint.pth.tar\"):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    checkpoint = {\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(checkpoint, filename)\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint_file, model, optimizer, lr):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    checkpoint = torch.load(checkpoint_file, map_location=config.DEVICE)\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "\n",
    "    # If we don't do this then it will just have learning rate of old checkpoint\n",
    "    # and it will lead to many hours of debugging \\:\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"lr\"] = lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9di90-PxTdK"
   },
   "source": [
    "**SUPERSAMPLING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_JtAouWt5J2L"
   },
   "source": [
    "Create the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "OUrdMmGJxWZs",
    "outputId": "7e497c46-2285-410e-c55f-3967a4a69d2e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fuel</th>\n",
       "      <th>per time cycling</th>\n",
       "      <th>super and rest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.05689</td>\n",
       "      <td>0.15860</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.05689</td>\n",
       "      <td>0.15860</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.05689</td>\n",
       "      <td>0.14560</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.05689</td>\n",
       "      <td>0.14222</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.05689</td>\n",
       "      <td>0.14222</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     fuel  per time cycling  super and rest\n",
       "0   1  0.05689           0.15860               0\n",
       "1   2  0.05689           0.15860               0\n",
       "2   3  0.05689           0.14560               0\n",
       "3   4  0.05689           0.14222               0\n",
       "4   5  0.05689           0.14222               0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data\n",
    "df = pd.read_csv('x train db3.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D78hwVt422rj",
    "outputId": "b3b55a67-d4c5-4673-e794-6bcf04278dee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'fuel', 'per time cycling', 'super and rest'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-4fADhDIxaL2",
    "outputId": "dc84892b-a3fd-4ff0-9c66-57d0e8b7c99e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transform to numpy\n",
    "data=np.array(df[['id', 'fuel', 'per time cycling', 'super and rest']])\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PwKk3T1iGs1t",
    "outputId": "2ff4c7a4-3b2e-4eef-86ae-d485e9bbe28a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 500, 500)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=np.transpose(data)\n",
    "\n",
    "data= data.reshape(4,500,500)\n",
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ZKVegzA6xob4"
   },
   "outputs": [],
   "source": [
    "#Divide into set\n",
    "\n",
    "w=500 #width\n",
    "h=500 #height\n",
    "s=256 #size\n",
    "step=32 #step\n",
    "\n",
    "\n",
    "idlist=[]\n",
    "\n",
    "for i in range(s//2-1,w-s//2,step):\n",
    "    for j in range(s//2-1,h-s//2,step):\n",
    "        idlist.append(data[0,i,j])\n",
    "\n",
    "\n",
    "dataclip=np.empty((0,3,256,256))\n",
    "\n",
    "for id in idlist:\n",
    "    #print(id)\n",
    "\n",
    "    row=int(id//h)\n",
    "    #print(row)\n",
    "\n",
    "    col=int(id-h*row -1)\n",
    "    #print(col)\n",
    "\n",
    "    #print(s)\n",
    "    minRow = row-s//2+1\n",
    "    maxRow = row+s//2+1\n",
    "    minCol = col-s//2+1\n",
    "    maxCol = col+s//2+1\n",
    "\n",
    "    #remove id column because we do not need it further\n",
    "    sample= data[1:,minRow:maxRow,minCol:maxCol]\n",
    "\n",
    "    #print(sample.shape)\n",
    "    dataclip=np.append(dataclip,[sample],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fgQygcnza8PD",
    "outputId": "3cff38ab-8285-4167-cfad-2e749ef5371f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 3, 256, 256)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataclip.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z-2u5pvXG31g"
   },
   "source": [
    "Repeat the process for labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "pZZkpi6t5Gd2",
    "outputId": "b9cf9d21-7ad8-48c4-d83e-841b8837e5ad"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>per green</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6.85954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6.85954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6.85954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6.85954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6.85954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  per green \n",
       "0   1     6.85954\n",
       "1   2     6.85954\n",
       "2   3     6.85954\n",
       "3   4     6.85954\n",
       "4   5     6.85954"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data\n",
    "df = pd.read_csv('y label db3.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I7R39LcVH1l4",
    "outputId": "aac11cb5-e017-4a65-bd66-f832fd0973c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'per green '], dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tCvLP4J3H4vE",
    "outputId": "51f06412-05e2-4c90-b472-5d64a733121d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transform to numpy\n",
    "data=np.array(df)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MoTXrvu7H-ZF",
    "outputId": "4c9c88c5-1791-4859-fc63-0f2507de9116"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 500, 500)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=np.transpose(data)\n",
    "\n",
    "data= data.reshape(2,500,500)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LruckJFCH-l8",
    "outputId": "3bc5c9db-d047-45b3-908e-0bdeddad96db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[63628.0, 63660.0, 63692.0, 63724.0, 63756.0, 63788.0, 63820.0, 63852.0, 79628.0, 79660.0, 79692.0, 79724.0, 79756.0, 79788.0, 79820.0, 79852.0, 95628.0, 95660.0, 95692.0, 95724.0, 95756.0, 95788.0, 95820.0, 95852.0, 111628.0, 111660.0, 111692.0, 111724.0, 111756.0, 111788.0, 111820.0, 111852.0, 127628.0, 127660.0, 127692.0, 127724.0, 127756.0, 127788.0, 127820.0, 127852.0, 143628.0, 143660.0, 143692.0, 143724.0, 143756.0, 143788.0, 143820.0, 143852.0, 159628.0, 159660.0, 159692.0, 159724.0, 159756.0, 159788.0, 159820.0, 159852.0, 175628.0, 175660.0, 175692.0, 175724.0, 175756.0, 175788.0, 175820.0, 175852.0]\n"
     ]
    }
   ],
   "source": [
    "#Divide into set\n",
    "\n",
    "w=500 #width\n",
    "h=500 #height\n",
    "s=256 #size\n",
    "step=32 #step\n",
    "\n",
    "\n",
    "idlisty=[]\n",
    "\n",
    "for i in range(s//2-1,w-s//2,step):\n",
    "    for j in range(s//2-1,h-s//2,step):\n",
    "        idlisty.append(data[0,i,j])\n",
    "\n",
    "print(idlisty)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "-O3jyH0cPj6b"
   },
   "outputs": [],
   "source": [
    "ylabel=np.empty((0,1,256,256))\n",
    "\n",
    "for id in idlisty:\n",
    "    #print(id)\n",
    "\n",
    "    row=int(id//h)\n",
    "    #print(row)\n",
    "\n",
    "    col=int(id-h*row -1)\n",
    "    #print(col)\n",
    "\n",
    "    #print(s)\n",
    "    minRow = row-s//2+1\n",
    "    maxRow = row+s//2+1\n",
    "    minCol = col-s//2+1\n",
    "    maxCol = col+s//2+1\n",
    "\n",
    "    #remove id column because we do not need it further\n",
    "    sample= data[1:,minRow:maxRow,minCol:maxCol]\n",
    "\n",
    "    #print(sample.shape)\n",
    "    ylabel=np.append(ylabel,[sample],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BJir1dK8aAsm",
    "outputId": "0c399630-7244-4755-80a9-be1f875bd432"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 1, 256, 256)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ylabel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7KNIdoX9aYMy",
    "outputId": "1c79cfcf-054d-4e6f-c9b8-fe75a3e85591"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 3, 256, 256)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#recreating 3 channels in total\n",
    "rgb = np.hstack((ylabel,ylabel,ylabel))\n",
    "rgb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sNo7-cJft3Pd"
   },
   "source": [
    "Create the test set / validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "M4bxfVddt5m6",
    "outputId": "19a6f0c0-2a07-4a1d-92f4-c5d717428f39"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>per green</th>\n",
       "      <th>per time cycling</th>\n",
       "      <th>super and rest</th>\n",
       "      <th>fuel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10.39321</td>\n",
       "      <td>0.04746</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10.39321</td>\n",
       "      <td>0.04746</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10.39321</td>\n",
       "      <td>0.04746</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10.39321</td>\n",
       "      <td>0.04746</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10.39321</td>\n",
       "      <td>0.04746</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  per green  per time cycling  super and rest    fuel\n",
       "0   1   10.39321           0.04746               0  0.0318\n",
       "1   2   10.39321           0.04746               0  0.0318\n",
       "2   3   10.39321           0.04746               0  0.0318\n",
       "3   4   10.39321           0.04746               0  0.0318\n",
       "4   5   10.39321           0.04746               0  0.0318"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data\n",
    "dft = pd.read_csv('test xn3.csv')\n",
    "dft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3iBR7r2-u9_t",
    "outputId": "751fc7f6-da76-43ed-ed32-6657fdec7fe1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'per green', 'per time cycling', 'super and rest', 'fuel'], dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dESP7maSvCVl",
    "outputId": "6fc7fd2a-8f84-49d6-a05a-122e0c77b19d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 500, 500)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transform to numpy\n",
    "datatest=np.array(dft[['id','per time cycling', 'super and rest', 'fuel']])\n",
    "datatest.shape\n",
    "\n",
    "datatest=np.transpose(datatest)\n",
    "\n",
    "datatest= datatest.reshape(4,500,500)\n",
    "datatest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IXHFtbeivbbx",
    "outputId": "cfc80f16-1ae3-4053-af9b-edc4023bdf3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[63628.0, 63660.0, 63692.0, 63724.0, 63756.0, 63788.0, 63820.0, 63852.0, 79628.0, 79660.0, 79692.0, 79724.0, 79756.0, 79788.0, 79820.0, 79852.0, 95628.0, 95660.0, 95692.0, 95724.0, 95756.0, 95788.0, 95820.0, 95852.0, 111628.0, 111660.0, 111692.0, 111724.0, 111756.0, 111788.0, 111820.0, 111852.0, 127628.0, 127660.0, 127692.0, 127724.0, 127756.0, 127788.0, 127820.0, 127852.0, 143628.0, 143660.0, 143692.0, 143724.0, 143756.0, 143788.0, 143820.0, 143852.0, 159628.0, 159660.0, 159692.0, 159724.0, 159756.0, 159788.0, 159820.0, 159852.0, 175628.0, 175660.0, 175692.0, 175724.0, 175756.0, 175788.0, 175820.0, 175852.0]\n"
     ]
    }
   ],
   "source": [
    "#Divide into set\n",
    "\n",
    "w=500 #width\n",
    "h=500 #height\n",
    "s=256 #size\n",
    "step=32 #step\n",
    "\n",
    "\n",
    "idlisttest=[]\n",
    "\n",
    "for i in range(s//2-1,w-s//2,step):\n",
    "    for j in range(s//2-1,h-s//2,step):\n",
    "        idlisttest.append(datatest[0,i,j])\n",
    "\n",
    "print(idlisttest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "qcruCGIIv97A"
   },
   "outputs": [],
   "source": [
    "datacliptest=np.empty((0,3,256,256))\n",
    "##UPDATE\n",
    "idvaltest=np.empty((0,256,256))\n",
    "\n",
    "for id in idlisttest:\n",
    "    #print(id)\n",
    "\n",
    "    row=int(id//h)\n",
    "    #print(row)\n",
    "\n",
    "    col=int(id-h*row -1)\n",
    "    #print(col)\n",
    "\n",
    "    #print(s)\n",
    "    minRow = row-s//2+1\n",
    "    maxRow = row+s//2+1\n",
    "    minCol = col-s//2+1\n",
    "    maxCol = col+s//2+1\n",
    "\n",
    "    #remove id column because we do not need it further\n",
    "    sample= datatest[1:,minRow:maxRow,minCol:maxCol]\n",
    "    idval=datatest[0,minRow:maxRow,minCol:maxCol]\n",
    "\n",
    "    #print(sample.shape)\n",
    "    datacliptest=np.append(datacliptest,[sample],axis=0)\n",
    "    idvaltest=np.append(idvaltest,[idval],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6SF-ZQipv6Gh",
    "outputId": "658d2098-d8c1-4932-f8c7-71709917ecf4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 3, 256, 256)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datacliptest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYf0i4iywhDG"
   },
   "source": [
    "Create the test label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4g2AVuWEwgDh",
    "outputId": "c9495c15-9847-4d63-d58a-86e0e7656af7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 500, 500)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transform to numpy\n",
    "datatesty=np.array(dft[['id', 'per green']])\n",
    "datatesty.shape\n",
    "\n",
    "datatesty=np.transpose(datatesty)\n",
    "\n",
    "datatesty= datatesty.reshape(2,500,500)\n",
    "datatesty.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2FiRpLj9w0a2",
    "outputId": "b264ac0a-f76c-4f0c-e34b-268c4169d8d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[63628.0, 63660.0, 63692.0, 63724.0, 63756.0, 63788.0, 63820.0, 63852.0, 79628.0, 79660.0, 79692.0, 79724.0, 79756.0, 79788.0, 79820.0, 79852.0, 95628.0, 95660.0, 95692.0, 95724.0, 95756.0, 95788.0, 95820.0, 95852.0, 111628.0, 111660.0, 111692.0, 111724.0, 111756.0, 111788.0, 111820.0, 111852.0, 127628.0, 127660.0, 127692.0, 127724.0, 127756.0, 127788.0, 127820.0, 127852.0, 143628.0, 143660.0, 143692.0, 143724.0, 143756.0, 143788.0, 143820.0, 143852.0, 159628.0, 159660.0, 159692.0, 159724.0, 159756.0, 159788.0, 159820.0, 159852.0, 175628.0, 175660.0, 175692.0, 175724.0, 175756.0, 175788.0, 175820.0, 175852.0]\n"
     ]
    }
   ],
   "source": [
    "#Divide into set\n",
    "\n",
    "w=500 #width\n",
    "h=500 #height\n",
    "s=256 #size\n",
    "step=32 #step\n",
    "\n",
    "\n",
    "idlisttesty=[]\n",
    "\n",
    "for i in range(s//2-1,w-s//2,step):\n",
    "    for j in range(s//2-1,h-s//2,step):\n",
    "        idlisttesty.append(datatesty[0,i,j])\n",
    "\n",
    "print(idlisttesty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "G5T1kHcdw9S-"
   },
   "outputs": [],
   "source": [
    "ytest=np.empty((0,1,256,256))\n",
    "\n",
    "for id in idlisttesty:\n",
    "    #print(id)\n",
    "\n",
    "    row=int(id//h)\n",
    "    #print(row)\n",
    "\n",
    "    col=int(id-h*row -1)\n",
    "    #print(col)\n",
    "\n",
    "    #print(s)\n",
    "    minRow = row-s//2+1\n",
    "    maxRow = row+s//2+1\n",
    "    minCol = col-s//2+1\n",
    "    maxCol = col+s//2+1\n",
    "\n",
    "    #remove id column because we do not need it further\n",
    "    sample= datatesty[1:,minRow:maxRow,minCol:maxCol]\n",
    "\n",
    "    #print(sample.shape)\n",
    "    ytest=np.append(ytest,[sample],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iMynsZ3vxqfq",
    "outputId": "ec53da8a-552f-4201-e38e-34038350eef1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 1, 256, 256)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzhdmFx0xs3S",
    "outputId": "5a34296a-8473-4374-be39-85c571020fce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 3, 256, 256)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#recreating 3 channels in total\n",
    "rgbtest = np.hstack((ytest,ytest,ytest))\n",
    "rgbtest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bu2UbtuLp1pE"
   },
   "source": [
    "**TRAIN THE MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "RQXT-vaRxIvq"
   },
   "outputs": [],
   "source": [
    "#Configurations\n",
    "\n",
    "disc = Discriminator(in_channels=3).to(DEVICE)\n",
    "gen = Generator(in_channels=3, features=64).to(DEVICE)\n",
    "opt_disc = optim.Adam(disc.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999),)\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "BCE = nn.BCEWithLogitsLoss()\n",
    "L1_LOSS = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ImFiZDRwxNJX",
    "outputId": "e90c04a1-f1ba-4dd3-93b7-a06d07dfc0b8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 2/2 [00:50<00:00, 25.13s/it, D_fake=0.372, D_real=0.507]\n",
      "100%|████████████████████████████████████████████████████████| 2/2 [00:49<00:00, 24.80s/it, D_fake=0.402, D_real=0.462]\n",
      "100%|████████████████████████████████████████████████████████| 2/2 [00:49<00:00, 24.98s/it, D_fake=0.422, D_real=0.546]\n",
      "100%|████████████████████████████████████████████████████████| 2/2 [00:49<00:00, 24.80s/it, D_fake=0.347, D_real=0.565]\n",
      "100%|████████████████████████████████████████████████████████| 2/2 [00:49<00:00, 24.57s/it, D_fake=0.321, D_real=0.596]\n",
      "100%|████████████████████████████████████████████████████████| 2/2 [00:48<00:00, 24.20s/it, D_fake=0.277, D_real=0.635]\n",
      "100%|████████████████████████████████████████████████████████| 2/2 [00:48<00:00, 24.30s/it, D_fake=0.285, D_real=0.674]\n",
      "100%|████████████████████████████████████████████████████████| 2/2 [00:48<00:00, 24.07s/it, D_fake=0.301, D_real=0.641]\n",
      "100%|█████████████████████████████████████████████████████████| 2/2 [00:48<00:00, 24.29s/it, D_fake=0.23, D_real=0.744]\n",
      "100%|████████████████████████████████████████████████████████| 2/2 [00:48<00:00, 24.27s/it, D_fake=0.195, D_real=0.714]\n",
      "100%|█████████████████████████████████████████████████████████| 2/2 [00:48<00:00, 24.19s/it, D_fake=0.17, D_real=0.773]\n",
      "100%|████████████████████████████████████████████████████████| 2/2 [00:48<00:00, 24.04s/it, D_fake=0.132, D_real=0.815]\n",
      "100%|████████████████████████████████████████████████████████| 2/2 [00:48<00:00, 24.33s/it, D_fake=0.121, D_real=0.836]\n",
      "100%|███████████████████████████████████████████████████████| 2/2 [00:48<00:00, 24.11s/it, D_fake=0.0998, D_real=0.858]\n",
      "100%|████████████████████████████████████████████████████████| 2/2 [00:48<00:00, 24.16s/it, D_fake=0.165, D_real=0.854]\n",
      "100%|███████████████████████████████████████████████████████| 2/2 [00:48<00:00, 24.31s/it, D_fake=0.0992, D_real=0.877]\n",
      "100%|████████████████████████████████████████████████████████| 2/2 [00:48<00:00, 24.36s/it, D_fake=0.0584, D_real=0.89]\n",
      "100%|██████████████████████████████████████████████████████| 2/2 [09:42<00:00, 291.11s/it, D_fake=0.0819, D_real=0.898]\n",
      "100%|███████████████████████████████████████████████████████| 2/2 [00:48<00:00, 24.18s/it, D_fake=0.0925, D_real=0.901]\n",
      "100%|███████████████████████████████████████████████████████| 2/2 [00:48<00:00, 24.19s/it, D_fake=0.0545, D_real=0.919]\n",
      "100%|███████████████████████████████████████████████████████| 2/2 [00:48<00:00, 24.14s/it, D_fake=0.0605, D_real=0.926]\n",
      "100%|████████████████████████████████████████████████████████| 2/2 [00:48<00:00, 24.19s/it, D_fake=0.225, D_real=0.934]\n",
      "100%|███████████████████████████████████████████████████████| 2/2 [00:48<00:00, 24.30s/it, D_fake=0.0795, D_real=0.908]\n",
      "100%|████████████████████████████████████████████████████████| 2/2 [00:45<00:00, 22.58s/it, D_fake=0.232, D_real=0.694]\n",
      "100%|█████████████████████████████████████████████████████████| 2/2 [00:49<00:00, 24.52s/it, D_fake=0.19, D_real=0.888]\n",
      "100%|█████████████████████████████████████████████████████████| 2/2 [00:49<00:00, 24.69s/it, D_fake=0.15, D_real=0.937]\n",
      "100%|████████████████████████████████████████████████████████| 2/2 [00:49<00:00, 24.56s/it, D_fake=0.0943, D_real=0.88]\n",
      "100%|███████████████████████████████████████████████████████| 2/2 [00:48<00:00, 24.22s/it, D_fake=0.0968, D_real=0.915]\n",
      "100%|███████████████████████████████████████████████████████| 2/2 [00:48<00:00, 24.26s/it, D_fake=0.0832, D_real=0.927]\n",
      "100%|███████████████████████████████████████████████████████| 2/2 [00:48<00:00, 24.42s/it, D_fake=0.0691, D_real=0.937]\n"
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "##ADDITION\n",
    "tensor_x = torch.Tensor(dataclip) # transform to torch tensor\n",
    "tensor_y = torch.Tensor(rgb)\n",
    "\n",
    "train_dataset = TensorDataset(tensor_x,tensor_y) # create your datset\n",
    "##\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True,num_workers=NUM_WORKERS,)\n",
    "\n",
    "g_scaler = torch.cuda.amp.GradScaler()\n",
    "d_scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_fn(disc, gen, train_loader, opt_disc, opt_gen, L1_LOSS, BCE, g_scaler, d_scaler,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "3UIp3rhc0wkQ"
   },
   "outputs": [],
   "source": [
    "#Test the model\n",
    "\n",
    "tensor_x = torch.Tensor(datacliptest) # transform to torch tensor\n",
    "tensor_y = torch.Tensor(rgbtest)\n",
    "\n",
    "val_dataset = TensorDataset(tensor_x,tensor_y) # create your datset\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "save_some_examples(gen, val_loader, 4, folder=\"C:\\\\Users\\\\15809\\\\Desktop\\\\pix final\") #Remember to choose the epoch and creat a folder on the desktop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "egRQpSBt18Xo"
   },
   "source": [
    "**SAVE THE RESULTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "s7e28dy72TH6"
   },
   "outputs": [],
   "source": [
    "#Import the saved data\n",
    "y= np.load(\"ypred.npy\")\n",
    "y2=y.reshape(BATCH_SIZE, 3, -1)\n",
    "\n",
    "idvaltest2=idvaltest.reshape(2,BATCH_SIZE,1,256,256) # total number/batch size=31\n",
    "###UPDATE\n",
    "idvaltest3=idvaltest2[1].reshape(32,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "id": "eGFAD6g92HUg",
    "outputId": "3e1b574b-251c-49c2-a8a8-1a976b8cd68f"
   },
   "outputs": [],
   "source": [
    "for i in range(len(idvaltest3)):\n",
    "    dfy=pd.DataFrame(idvaltest3[i,:],columns=['id'])\n",
    "    dfy['ch1']= y2[i,0,:]\n",
    "    dfy['ch2']= y2[i,1,:]\n",
    "    dfy['ch3']= y2[i,2,:]\n",
    "    dfy.to_csv(f'./_pred_{i}.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
